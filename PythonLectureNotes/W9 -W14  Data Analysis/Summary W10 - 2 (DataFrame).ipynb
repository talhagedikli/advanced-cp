{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The DataFrame is conceptually a two-dimensional series object, where there's an index and multiple columns of  content, with each column having a label. \n",
    "- In fact, the distinction between a column and a row is really only a  conceptual distinction. \n",
    "- you can think of the DataFrame itself as simply a two-axes labeled array.\n",
    "- It's just like excel table in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Dataframe from dictionaries and series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by importing our pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating Dataframe - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "author = ['Mehmet', 'Ali', 'Ayberk', 'Batuhan']\n",
    "article = [210, 211, 114, 178]\n",
    "  \n",
    "auth_series    = pd.Series(author)\n",
    "article_series = pd.Series(article)\n",
    "article_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame = { 'Author': auth_series, 'Article': article_series }\n",
    "#this is a dictionary\n",
    "#convert the dictionary to a dataframe\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "result = pd.DataFrame(frame)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to add series externally in dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "age = [17, 21, 24,32]\n",
    "\n",
    "result['Age'] = pd.Series(age)\n",
    "\n",
    "result\n",
    "#We have added one more series externally named as age of the authors, \n",
    "# then directly added this series in the pandas dataframe. \n",
    "# Remember one thing if any value is missing then by default \n",
    "# it will be converted into NaN value i.e null by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "town = [\"Ist\", \"Ank\", \"Trb\"]\n",
    "  \n",
    "result['Town'] = pd.Series(town)\n",
    "  \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataframe - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create three school records for students and their  class grades.\n",
    "# I'll create each as a series which has a student name, the class name, and the score. \n",
    "record1 = pd.Series({    'Name': 'Alice',\n",
    "                        'Class': 'Physics',\n",
    "                        'Score': 85})\n",
    "\n",
    "record2 = pd.Series({    'Name': 'Jack',\n",
    "                        'Class': 'Chemistry',\n",
    "                        'Score': 82})\n",
    "\n",
    "record3 = pd.Series({   'Name': 'Helen',\n",
    "                        'Class': 'Biology',\n",
    "                        'Score': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record1['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like a Series, the DataFrame object is index. Here I'll use a group of series, where each series \n",
    "# represents a row of data. Just like the Series function, we can pass in our individual items\n",
    "# in an array, and we can pass in our index values as a second arguments\n",
    "df = pd.DataFrame([record1, record2, record3], index=['school1', 'school2', 'school1'])\n",
    "\n",
    "# And just like the Series we can use the head() function to see the first several rows of the\n",
    "# dataframe, including indices from both axes, and we can use this to verify the columns and the rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative method is that you could use --a list of dictionaries--, \n",
    "# where each dictionary represents a row of data.\n",
    "\n",
    "students = [{'Name': 'Alice',\n",
    "              'Class': 'Physics',\n",
    "              'Score': 85},\n",
    "            {'Name': 'Jack',\n",
    "             'Class': 'Chemistry',\n",
    "             'Score': 82},\n",
    "            {'Name': 'Helen',\n",
    "             'Class': 'Biology',\n",
    "             'Score': 90}]\n",
    "#df = pd.DataFrame([record1, record2, record3],\n",
    "#                  index=['school1', 'school2', 'school1'])\n",
    "\n",
    "df = pd.DataFrame(students, index=['school1', 'school2', 'school1'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] # you can read columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['school2'] # you canNOT read rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# School1 has multiple rows. \n",
    "# Lets query for school1 records\n",
    "df.loc['school1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1', 'Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use transpose\n",
    "df.T # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T['school1'] # recall that df['school1'] is not possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can call .loc on the transpose to get the student names only\n",
    "df.T['Name'] # we will have an error for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.loc['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc['school1']['Name'] # called chaining. Returns a copy\n",
    "# If you are #chanGing# data, though this is an important distinction and can be a source of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1', 'Name'] \n",
    "# remember we also did the same thing before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2']['Name'] = 'mehmet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school2','Name'] = 'mehmet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1'] = \"a\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SLICING\n",
    "If you need more than one columns...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example, where we ask for all the names and scores for all schools using the \n",
    "# .loc operator.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1',['Name', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[: , ['Name', 'Score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"school1\", :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop('school1', inplace=True) #gives a copy of df with the given rows removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if we look at our original DataFrame we see the data is still intact.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop has two interesting optional parameters. \n",
    "# 1) inplace\n",
    "# if it's set to true, the DataFrame will be updated in place, instead of a copy being returned. \n",
    "# 2) axis \n",
    "# The second parameter is the axes, which should be dropped. \n",
    "# 0, ==> Row,    1 ==> column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, lets make a copy of a DataFrame using .copy()\n",
    "copy_df  = df.copy()\n",
    "copy_df2 = df\n",
    "copy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did we do this and use a copy function instead of creating a copy with copy_df = df.copy()\n",
    "\n",
    "#later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets drop the name column in this copy\n",
    "copy_df.drop(\"school2\", inplace=True, axis=0)\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, adding a new column to the DataFrame is as easy as assigning it to some value using\n",
    "# the indexing operator. For instance, if we wanted to add a class ranking column with default \n",
    "# value of None, we could do so by using the assignment operator after the square brackets.\n",
    "# This broadcasts the default value to the new column immediately.\n",
    "\n",
    "df['ClassRanking'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this lecture you've learned about the data structure you'll use the most in pandas, the DataFrame. The \n",
    "dataframe is indexed both by row and column, and you can easily select individual rows and project the columns \n",
    "you're interested in using the familiar indexing methods from the Series class. You'll be gaining a lot of \n",
    "experience with the DataFrame in the content to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ClassRanking'] = [22,21,20]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['school1', \"Score\"] =23\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALIASING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc['school2'] = 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATAFRAME: INDEXING AND LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas mades it easy to turn a CSV into a dataframe, we just call read_csv()\n",
    "df = pd.read_csv('datasets/Admission_Predict.csv',delimiter=\";\", index_col=0)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Chance of Admit '])\n",
    "#or\n",
    "#X = df[['gre score', 'toefl score', 'university rating', 'sop', 'lor', 'cgpa','research']]\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better representation \n",
    "df.columns = [x.lower().strip() for x in df.columns]\n",
    "# And we'll take a look at the results\n",
    "df.head(5)\n",
    "\n",
    "# And let's look at the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_mask = df['chance of admit'] > 0.7 # we can use this masking to pick the students\n",
    "#whose chance of admit is larger than 0.7\n",
    "admit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df['chance of admit'] > 0.7).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorthand way of writing above is\n",
    "df[ df['chance of admit'] > 0.7 ]  #it generates a copy of dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['chance of admit'] > 0.7) & (df['chance of admit'] < 0.9)\n",
    "df['chance of admit'].gt(0.7) & df['chance of admit'].lt(0.9)\n",
    "df['chance of admit'].gt(0.7).lt(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 is over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Indexing - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/Admission_Predict.csv\", index_col=0, delimiter=\";\")\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOP'] = df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('CGPA')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/MPG.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manufacturer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = df[df['manufacturer'] == \"audi\"]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['manufacturer', 'model'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"audi\", \"a4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"audi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the NaN value sin dataframes\n",
    "\n",
    "df.fillna(0, inplace=True)# if inplace is True, the original df is modified. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying functions to dataframes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([[9, 16], [4,25], [100,64]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sqrt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=0) #axis = 0 means sum the elements in a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=1)#axis = 1 means sum the elements in a row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging Dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# First we create two DataFrames, staff and students.\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion'},\n",
    "                         {'Name': 'James', 'Role': 'Grader'}])\n",
    "# And lets index these staff by name\n",
    "staff_df = staff_df.set_index('Name')\n",
    "# Now we'll create a student dataframe\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business'},\n",
    "                           {'Name': 'Mike', 'School': 'Law'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering'}])\n",
    "# And we'll index this by name too\n",
    "student_df = student_df.set_index('Name')\n",
    "\n",
    "# And lets just print out the dataframes\n",
    "print(staff_df.head())\n",
    "print(student_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True) #Outer = union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='inner', left_index=True, right_index=True) #innter = intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='left', left_index=True, right_index=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='right', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('datasets/mpg.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupy - Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby(\"manufacturer\").agg({\"cty\":np.average}) # 3 values and 2 nan values, it will be divided by 5.  \n",
    "df.groupby(\"manufacturer\").agg({\"cty\":np.nanmean}) #ignores NaN values=> diveded by 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=['manufacturer','cty','hwy','trans']\n",
    "df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].groupby('manufacturer').transform(np.nanmean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('manufacturer').filter(lambda x: np.nanmean(x['cty'])>20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby - Applying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"datasets/mpg.csv\")\n",
    "# And lets just include some of the columns we were interested in previously\n",
    "df=df[['manufacturer','cty']]\n",
    "df.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_cty(group):\n",
    "    # group is a dataframe just of whatever we have grouped by, e.g. manufacturer, \n",
    "    #hence we can treat this as the complete dataframe\n",
    "    avg=np.nanmean(group[\"cty\"])\n",
    "    #print('avg',avg)\n",
    "    # now broadcast our formula and create a new column\n",
    "    group[\"cty_diff\"]=np.abs(avg-group[\"cty\"])\n",
    "    return group\n",
    "calc_mean_cty(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIVOT TABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"datasets/mpg.csv\", index_col=0)\n",
    "df.pivot_table(values='cty', index='class', columns='cyl', aggfunc=[np.mean, np.max,np.min])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
